{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "login(hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "iframe_html = \"\"\"\n",
    "<iframe src=\"https://huggingface.co/datasets/DIBT/MPEP_RUSSIAN/embed/viewer/train\" width=\"80%\" height=\"560px\"></iframe>\n",
    "\"\"\"\n",
    "display(HTML(iframe_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"DIBT/MPEP_RUSSIAN\")\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from distilabel.steps import ExpandColumns\n",
    "from distilabel.llms import InferenceEndpointsLLM\n",
    "from distilabel.pipeline import Pipeline\n",
    "from distilabel.steps import LoadDataFromHub\n",
    "from distilabel.steps.tasks import TextGeneration, UltraFeedback\n",
    "from distilabel.steps import CombineColumns\n",
    "from distilabel.steps import step\n",
    "from distilabel.steps.typing import GeneratorStepOutput\n",
    "\n",
    "llama70B = InferenceEndpointsLLM(\n",
    "    model_id=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    tokenizer_id=\"meta-llama/Meta-Llama-3.1-70B-Instruct\",\n",
    "    generation_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    ")\n",
    "llama405B = InferenceEndpointsLLM(\n",
    "    model_id=\"meta-llama/Meta-Llama-3.1-405B-Instruct-FP8\",\n",
    "    tokenizer_id=\"meta-llama/Meta-Llama-3.1-405B-Instruct-FP8\",\n",
    "    generation_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    ")\n",
    "\n",
    "with Pipeline(name=\"synthetic-data-with-llama3-russian-dibt\") as pipeline:\n",
    "    # load dataset with prompts\n",
    "    load_dataset = LoadDataFromHub(\n",
    "        repo_id=\"DIBT/MPEP_RUSSIAN\",\n",
    "        output_mappings={\"target\": \"instruction\"}\n",
    "    )\n",
    "\n",
    "    # generate two responses\n",
    "    generate = [\n",
    "        TextGeneration(\n",
    "            llm=llama70B,\n",
    "            output_mappings={\"generation\": \"response\"}\n",
    "        ),\n",
    "        TextGeneration(\n",
    "            llm=llama405B,\n",
    "            output_mappings={\"generation\": \"response\"}\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # combine responses into one col\n",
    "    combine = CombineColumns(\n",
    "        columns=[\"response\", \"model_name\"],\n",
    "        output_columns=[\"responses\", \"model_names\"]\n",
    "    )\n",
    "\n",
    "    # rate responses with 405B LLM-as-a-judge\n",
    "    rate = UltraFeedback(\n",
    "        aspect=\"overall-rating\", \n",
    "        llm=llama405B, \n",
    "        input_mappings={\"generations\": \"responses\"}\n",
    "    )\n",
    "\n",
    "    # define and run pipeline\n",
    "    load_dataset >> generate >> combine >> rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distiset=pipeline.dry_run()\n",
    "distiset=pipeline.run(use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiset['default']['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiset.push_to_hub(\n",
    "    \"ZennyKenny/russian-dibt-llama-responses_new\",\n",
    "    token=hf_token,\n",
    "    private=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iframe_html = \"\"\"\n",
    "<iframe src=\"https://huggingface.co/datasets/ZennyKenny/russian-dibt-llama-responses/embed/viewer/train\" width=\"80%\" height=\"560px\"></iframe>\n",
    "\"\"\"\n",
    "display(HTML(iframe_html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
